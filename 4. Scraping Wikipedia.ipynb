{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = pd.read_csv('stazioni mancanti.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regioni = []\n",
    "\n",
    "for codice in stazioni[1]:\n",
    "    regioni.append(requests.get(\"http://www.viaggiatreno.it/infomobilita/resteasy/viaggiatreno/regione/\" + codice).text)\n",
    "\n",
    "stazioni['regioni'] = regioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for riga in stazioni.itertuples():\n",
    "    if riga[3]:\n",
    "        testo = requests.get(\"http://www.viaggiatreno.it/infomobilita/resteasy/viaggiatreno/dettaglioStazione/\" + riga[2] + '/' + riga[3]).text\n",
    "        testo = testo.split(\"\\\"lat\\\":\")\n",
    "        testo = testo[1].split(\",\\\"lon\\\":\")\n",
    "        lat.append(testo[0])\n",
    "        testo = testo[1].split(\",\\\"latMappaCitta\\\"\")\n",
    "        lon.append(testo[0])\n",
    "    else:\n",
    "        lat.append('')\n",
    "        lon.append('')\n",
    "\n",
    "stazioni['lat'] = lat\n",
    "stazioni['lon'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "\n",
    "for riga in stazioni.itertuples():\n",
    "    if riga[4] and riga[5]:\n",
    "        page = requests.get(\"https://wikidata.reconci.link/it/api?queries=%7B%22q0%22%3A%7B%22query%22%3A%22stazione+\"+\n",
    "                            riga[1]+\"%22%2C%22properties%22%3A%5B%7B%22pid%22%3A%22P625%22%2C%22v%22%3A%22\"+riga[4]+\n",
    "                            \"%2C\"+riga[5]+\"%22%7D%5D%7D%7D\")\n",
    "        if page.text == \"{\\\"q0\\\":{\\\"result\\\":[]}}\":\n",
    "            print(riga[1], \"nessun match\")\n",
    "            ids.append('')\n",
    "            continue\n",
    "        id = page.text.split(\",\\\"id\\\":\\\"\")\n",
    "        id = id[1].split(\"\\\"\")[0]\n",
    "        ids.append(id)\n",
    "        print(riga[1], id)\n",
    "    else:\n",
    "        page = requests.get(\"https://wikidata.reconci.link/it/api?queries=%7B%22q0%22%3A%7B%22query%22%3A%22stazione+\"+riga[1]+\"%22%7D%7D\")\n",
    "        if page.text == \"{\\\"q0\\\":{\\\"result\\\":[]}}\":\n",
    "            print(riga[1], \"nessun match\")\n",
    "            ids.append('')\n",
    "            continue\n",
    "        id = page.text.split(\",\\\"id\\\":\\\"\")\n",
    "        id = id[1].split(\"\\\"\")[0]\n",
    "        ids.append(id)\n",
    "        print(riga[1], id)\n",
    "\n",
    "stazioni['ids'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_urls = []\n",
    "\n",
    "for riga in stazioni.itertuples():\n",
    "    if riga[6]:\n",
    "        page = requests.get(\"https://www.wikidata.org/wiki/\" + riga[6])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        pagina = soup.find(\"span\",class_=\"wikibase-sitelinkview-page\",lang=\"it\")\n",
    "        if pagina:\n",
    "            url = pagina.find(\"a\")\n",
    "            wiki_urls.append(url['href'])\n",
    "        else:\n",
    "            wiki_urls.append('')\n",
    "    else:\n",
    "        wiki_urls.append('')\n",
    "\n",
    "stazioni['wiki_urls'] = wiki_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagine_ok = []\n",
    "errori = 0\n",
    "cose_sconosciute = [[],[]]\n",
    "\n",
    "for riga in stazioni.itertuples():\n",
    "    if riga[7]:\n",
    "\n",
    "        page = requests.get(riga[7])\n",
    "        a = page.status_code\n",
    "\n",
    "        # scrape webpage\n",
    "        if(a==200):\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            if soup.find(\"th\", text=\"Binari\"):\n",
    "                binari = soup.find(\"th\", text=\"Binari\").find_next_sibling(\"td\").text\n",
    "                pagine_ok.append(binari)\n",
    "            else:\n",
    "                errori+=1\n",
    "                pagine_ok.append('')\n",
    "\n",
    "        elif(a==404):\n",
    "            errori+=1\n",
    "            pagine_ok.append('')\n",
    "\n",
    "        else:\n",
    "            cose_sconosciute[0].append(riga[7])\n",
    "            cose_sconosciute[1].append(a)\n",
    "            pagine_ok.append('')\n",
    "\n",
    "        print(riga[1], binari)\n",
    "    else:\n",
    "        pagine_ok.append('')\n",
    "\n",
    "print(len(pagine_ok), errori)\n",
    "\n",
    "\n",
    "stazioni['binari'] = pagine_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni_ok = stazioni[stazioni['binari'].notnull()]\n",
    "stazioni_ok['binari'] = stazioni_ok['binari'].str.replace('\\n', '')\n",
    "stazioni_ok['binari_ok'] = stazioni_ok['binari'].str.replace(r'([0-9]*).*', r'\\1', regex=True)\n",
    "stazioni_ok = stazioni_ok[stazioni_ok['binari_ok'] != '']\n",
    "stazioni_ok['binari_ok'].apply(int)\n",
    "stazioni_ok.rename(columns={\"0\":\"nome_stazione\", \"1\":\"id_staz\"}, inplace=True)\n",
    "stazioni_ok.set_index(\"id_staz\", inplace=True, drop=True)\n",
    "stazioni_ok.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "stazioni_ok.to_csv('binari wiki.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
